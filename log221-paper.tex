\documentclass[a4paper]{article}

\usepackage{preamble}
\usepackage{log221-paper-macros}
\usepackage{showkeys}

\title{Cut admissibility by normalization}
\author{Frank Tsai}

\begin{document}

\maketitle

\section{Lambda calculus}
\label{sec:0001}

\begin{definition}
  A term $\Gamma \vdash t : A$ is in \emph{normal form}, denoted by $\nf{\Gamma}{A}(t)$, if the major argument of every eliminator in $t$ is a variable.
\end{definition}

\begin{theorem}
  If $\Gamma \vdash t : A$ then there exists $t'$ such that $t = t'$ and $\nf{\Gamma}{A}(t)$.
\end{theorem}
\begin{proof}[Proof (failed attempt).]
  We proceed by induction on the typing derivation $\Gamma \vdash t : A$.
  \begin{itemize}
  \item[\rVar] Since there is no eliminator in the variable $x$, it is already in normal form.
  \item[\rProdI] By the induction hypothesis, there exist $a'$ and $b'$ in normal form such that $a = a'$ and $b = b'$; then $\tmPair{a}{b} = \tmPair{a'}{b'}$ and the latter is evidently in normal form.
  \item[\rSumIl] This is analogous to the previous case: apply the induction hypothesis and then the claim becomes self-evident.
    $\rSumIr$ is analogous.
  \item[\rFunI] Evident by the induction hypothesis.
  \item[\rEmpE] By the induction hypothesis, there exists $e'$ such that $e = e'$ and $e'$ is in normal form; then $\tmAbort{e} = \tmAbort{e'}$, but the induction hypothesis is too weak to show that $e'$ is convertible to a variable.
    We are stuck.
  \item[\rProdE] We have $\tmDestruct{p}{c} = \tmDestruct{p'}{c'}$ with $p'$ and $c'$ in normal form.
    Again, we cannot show that $p'$ is convertible to a variable, so we are stuck.
  \item[\rSumE] Same problem as the previous case.
  \item[\rFunE] Same problem as the previous case.
  \end{itemize}
\end{proof}

\begin{definition}
  We define a family of computability predicates, $\comp{\Gamma}{A}$, as follows:
  \begin{itemize}
  \item[$\tpEmp$:] $\comp{\Gamma}{\tpEmp}(t)$ iff $t$ is convertible to a normal form.
  \item[$A \times B$:] $\comp{\Gamma}{A \times B}(t)$ iff $t$ is convertible to $\tmPair{a}{b}$ for some terms $a$ and $b$ such that $\comp{\Gamma}{A}(a)$ and $\comp{\Gamma}{B}(b)$, or $t$ is convertible to $\tmAbort{e}$ for some term $e$ such that $\comp{\Gamma}{\tpEmp}(e)$.
  \item[$A + B$:] $\comp{\Gamma}{A + B}(t)$ iff $t$ is convertible to $\tmInl{a}$ for some term $a$ such that $\comp{\Gamma}{A}(a)$, or $t$ is convertible to $\tmInr{b}$ for some term $b$ such that $\comp{\Gamma}{B}(b)$, or $t$ is convertible to a term $s$ such that $\nf{\Gamma}{A + B}(s)$, or $t$ is convertible to $\tmAbort{e}$ for some term $e$ such that $\comp{\Gamma}{\tpEmp}(e)$.
  \item[$A \to B$:] $\comp{\Gamma}{A \to B}(t)$ iff $t$ is convertible to $\tmLam{x}{b}$ such that for all $\Gamma \subseteq \Delta$, if $\comp{\Delta}{A}(a)$ then $\comp{\Delta}{B}(b[a/x])$, or $t$ is convertible to $\tmAbort{e}$ for some term $e$ such that $\comp{\Gamma}{\tpEmp}(e)$.
  \end{itemize}
  We extend this definition to tuples in the evident way: $\comp{\Delta}{\Gamma}(\gamma)$ iff $\comp{\Delta}{A}(\gamma(x))$ for all $x : A \in \Gamma$.
\end{definition}

\begin{lemma}\label{thm:0002}
  If $\comp{\Gamma}{A}(a)$ and $a = a'$, then $\comp{\Gamma}{A}(a')$.
\end{lemma}
\begin{proof}
  Note that convertibility is a congruence; hence the result follows easily by induction on $A$.
\end{proof}

\begin{lemma}\label{thm:0000}
  If $\Gamma \vdash e : \tpEmp$ and $\comp{\Gamma}{\tpEmp}(e)$, then $\comp{\Gamma}{A}(\tmAbort{e})$.
\end{lemma}
\begin{proof}
  We proceed by induction on $A$.
  \begin{itemize}
  \item[$\tpEmp$] By \rEmpe, $\tmAbort{e}$ is convertible to $e$; then by definition, $e$ is convertible to a normal form, so $\tmAbort{e}$ is convertible to a normal form by transitivity.
    Hence $\comp{\Gamma}{\tpEmp}(\tmAbort{e})$.
  \item[$A \times B$] $\tmAbort{e}$ is evidently convertible to itself; hence $\comp{\Gamma}{A \times B}(\tmAbort{e})$ follows by definition.
  \end{itemize}
  All other cases are similar.
\end{proof}

\begin{lemma}\label{thm:0001}
  If $\Delta \subseteq \Delta'$ and $\comp{\Delta}{A}(a)$, then $\comp{\Delta'}{A}(a)$.
  This result easily generalizes to substitution: if $\comp{\Delta}{\Gamma}(\gamma)$, then $\comp{\Delta'}{\Gamma}(\gamma)$.
\end{lemma}
\begin{proof}
  By inspection, typing and conversion are closed under context weakening; hence the result follows easily by induction on $A$.
\end{proof}

\begin{theorem}[Fundamental Theorem]
  Let $\Gamma \vdash t : D$ be a term and $\Delta$ be an arbitrary context.
  If $\comp{\Delta}{\Gamma}(\gamma)$ then $\comp{\Delta}{D}(t[\gamma])$.
\end{theorem}
\begin{proof}
  We proceed by induction on the typing derivation.
  \begin{itemize}
  \item[\rVar] Since $x[\gamma] = \gamma(x)$ and $\comp{\Delta}{D}(\gamma(x))$ by definition, the result is immediate.
  \item[\rEmpE] By the induction hypothesis, we have $\comp{\Delta}{\tpEmp}(e[\gamma])$; hence $\comp{\Delta}{D}(\tmAbort{e[\gamma]})$ by \cref{thm:0000}.
  \item[\rProdI] By the induction hypothesis, we have $\comp{\Delta}{A}(a[\gamma])$ and $\comp{\Delta}{B}(b[\gamma])$; hence it follows by definition that $\comp{\Delta}{A \times B}(\tmPair{a[\gamma]}{b[\gamma]})$.
    Henceforth, we will not state the induction hypothesis explicitly.
  \item[\rProdE] There are two cases to consider: (1) $p[\gamma] = \tmAbort{e}$ for some $e$ such that $\comp{\Delta}{\tpEmp}(e)$, or (2) $p[\gamma] = \tmPair{a}{b}$ for some $a$ and $b$ such that $\comp{\Delta}{A}(a)$ and $\comp{\Delta}{B}(b)$.

    The former case is easy: since $\tmDestruct{p[\gamma]}{c[\gamma]} = \tmAbort{e}$ by $\rs$, the result follows from \cref{thm:0000}.

    In the latter case, it suffices to show that $\comp{\Delta}{C}(c[\gamma,a/x,b/y])$ by $\rProdb$.
    Since $\comp{\Delta}{\Gamma}(\gamma)$, $\comp{\Delta}{A}(a)$, and $\comp{\Delta}{B}(b)$, we have $\comp{\Delta}{\Gamma,x : A,y : B}(\gamma,a/x,b/y)$; hence the induction hypothesis gives $\comp{\Delta}{C}(c[\gamma,a/x,b/y])$.
  \item[\rSumIl] Since $\comp{\Delta}{A}(a[\gamma])$, we have $\comp{\Delta}{A+B}(\tmInl{a[\gamma]})$ by definition.
    \rSumIr is analogous.
  \item[\rSumE] There are four cases to consider: (1) $s[\gamma] = \tmAbort{e}$ for some $e$ such that $\comp{\Delta}{\tpEmp}(e)$, or (2) $s[\gamma] = \tmInl{a}$ for some $\comp{\Delta}{A}(a)$, or (3) $s[\gamma] = \tmInr{b}$ for some $\comp{\Delta}{B}(b)$, or (4) $s[\gamma] = s'$ for some $\nf{\Delta}{A+B}(s')$.

    Case (1) is an immediate consequence of $\rs$ and \cref{thm:0000}; Cases (2) and (3) are analogous, so we will show Case (2) only.
    
    By $\rSumbl$, it suffices to show $\comp{\Delta}{C}(c[\gamma,a/x])$; since $\comp{\Delta}{\Gamma,x : A}(\gamma,a/x)$, this is an immediate consequence of the induction hypothesis.
  \item[\rFunI] It suffices to show that for all $\Delta \subseteq \Delta'$, if $\comp{\Delta'}{A}(a)$, then $\comp{\Delta'}{B}(t[\gamma,a/x])$.
    Fix $\Delta \subseteq \Delta'$ and suppose that $\comp{\Delta'}{A}(a)$.
    Since $\comp{\Delta}{\Gamma}(\gamma)$, we have $\comp{\Delta'}{\Gamma}(\gamma)$ by \cref{thm:0001}; hence we have $\comp{\Delta'}{\Gamma,x:A}(\gamma,a/x)$.
    Then the result follows by the induction hypothesis.
  \item[\rFunE] There are two cases to consider: (1) $f[\gamma]$ is convertible to $\tmAbort{e}$ for some $e$ such that $\comp{\Delta}{\tpEmp}(e)$, or (2) $f[\gamma]$ is convertible to $\tmLam{x}{b}$ such that for all $\Delta \subseteq \Delta'$, if $\comp{\Delta'}{A}(a)$, then $\comp{\Delta'}{B}(b[a/x])$.
    Again, the first case is trivial by $\rs$ and \cref{thm:0000}.

    In Case (2), by $\rFunb$, it suffices to show $\comp{\Delta}{C}(c[\gamma,(b[a[\gamma]/x])/y)$.
    Choose $\Delta' = \Delta,y : B$; then we have $\comp{\Delta'}{\Gamma}(\gamma)$ and $\comp{\Delta'}{A}(a[\gamma])$ by \cref{thm:0001}, and moreover $\comp{\Delta'}{B}(b[a[\gamma]/x])$.
    Hence the result follows by the induction hypothesis.
  \end{itemize}
\end{proof}

\begin{lemma}
  If $z : D \in \Gamma$, then $\comp{\Gamma}{D}(z)$.
\end{lemma}
\begin{proof}[Proof (failed attempt).]
  We proceed by induction on $D$.
  \begin{itemize}
  \item[$\tpEmp$] This case is trivial since $z$ is a variable.
  \item[$A \times B$] By $\rProde$, it suffices to verify that $\comp{\Gamma}{A}(\tmDestruct{z}{x})$ and $\comp{\Gamma}{B}(\tmDestruct{z}{y})$.
    We do not know if they are convertible to a variable, so the induction hypothesis does not apply.
    We are stuck.
  \item[$A + B$] ...
  \item[$A \to B$] By $\rFune$, we check that for all $\Gamma \subseteq \Delta$, if $\comp{\Delta}{A}(a)$, then $\comp{\Delta}{B}(\tmApp{z}{a}{y})$.
    Yet again, we are stuck.
  \end{itemize}
\end{proof}

We want to show that every variable can be reflected into a computable element.
The na\"ive induction fails because the induction hypothesis is too weak.
We embed variables into a larger class of elements called neutral elements.

\todo This is completely wrong.
\begin{definition}
  We define the \emph{neutral element} predicates, $\neu{\Gamma}{A}(t)$, as follows:
  \begin{itemize}
  \item[] $\neu{\Gamma}{A}(x)$ if $x : A \in \Gamma$.
  \item[] $\neu{\Gamma}{\tpEmp}(t)$ iff $\comp{\Gamma}{\tpEmp}(t)$.
  \item[] $\neu{\Gamma}{A}(\tmDestruct{t}{x\tpAnno{A}})$ if $\neu{\Gamma}{A \times B}(t)$.
  \item[] $\neu{\Gamma}{B}(\tmDestruct{t}{y\tpAnno{B}})$ if $\neu{\Gamma}{A \times B}(t)$.
  \item[] $\neu{\Gamma}{A + B}(t)$ iff $\comp{\Gamma}{A + B}(t)$.
  \item[] $\neu{\Gamma}{B}(\tmApp{t}{a}{y\tpAnno{B}})$ if $\neu{\Gamma}{A \to B}(t)$ and $a$ is convertible to a normal form.
  \item[] $\neu{\Delta}{A}(t)$ if $\neu{\Gamma}{A}(t)$ and $\Gamma \subseteq \Delta$.
  \end{itemize}
\end{definition}

\begin{theorem}[Tait's Yoga]
  Every neutral element can be reflected into a computable element and every computable element can be reified into a normal form.
\end{theorem}
\begin{proof}
  Let $t$ be an arbitrary well-typed term; we proceed by induction on its type.
  \begin{itemize}
  \item[$\tpEmp$] If $\neu{\Gamma}{\tpEmp}(t)$, then $\comp{\Gamma}{\tpEmp}(t)$ by definition.
    If $\comp{\Gamma}{\tpEmp}(t)$, then $t$ is convertible to a variable, which evidently has no eliminator; hence $t$ is convertible to a normal form.
  \item[$A \times B$] If $\neu{\Gamma}{A \times B}(t)$, then $\neu{\Gamma}{A}(\tmDestruct{t}{x\tpAnno{A}})$ and $\neu{\Gamma}{B}(\tmDestruct{t}{y\tpAnno{B}})$.
    By the induction hypothesis, both neutral elements can be reflected into computable elements; hence $\comp{\Gamma}{A \times B}(\tmPair{\tmDestruct{t}{x\tpAnno{A}}}{\tmDestruct{t}{y\tpAnno{B}}})$ follows by definition.
    Note that $t = \tmPair{\tmDestruct{t}{x\tpAnno{A}}}{\tmDestruct{t}{y\tpAnno{B}}}$ by \rProde.

    If $\comp{\Gamma}{A \times B}(t)$, then $\comp{\Gamma}{A}(\tmDestruct{t}{x\tpAnno{A}})$ and $\comp{\Gamma}{B}(\tmDestruct{t}{y\tpAnno{B}})$.
    By the induction hypothesis, both terms can be reified into normal forms; hence $\tmPair{\tmDestruct{t}{x\tpAnno{A}}}{\tmDestruct{t}{y\tpAnno{B}}}$ is convertible to a normal form.
  \item[$A + B$] If $\neu{\Gamma}{A + B}(t)$, then $\comp{\Gamma}{A + B}(t)$ by definition.
    If $\comp{\Gamma}{A + B}(t)$, then there are three cases to consider: (1) $t$ is convertible to $\tmInl{a}$ for some $a$ such that $\comp{\Gamma}{A}(a)$, or (2) $t$ is convertible to $\tmInr{b}$ for some $b$ such that $\comp{\Gamma}{B}(b)$, or (3) $t$ is convertible to $\tmAbort{e}$ for some $e$ such that $\comp{\Gamma}{\tpEmp}(e)$.

    Cases (1) and (2) are analogous, so we check Case (1) only.
    By the induction hypothesis, $a$ can be reified into a normal form; hence $\tmInl{a}$ is convertible to a normal form.

    In Case (2), by definition, $e$ is convertible to a variable; hence $\tmAbort{e}$ is convertible to a normal form.
  \item[$A \to B$] Suppose that $\neu{\Gamma}{A \to B}(t)$.
    Since every function is convertible to a lambda term via $\rFune$, it suffices to show that for all $\Gamma \subseteq \Delta$, if $\comp{\Delta}{A}(a)$, then $\comp{\Gamma}{B}(\tmApp{t}{a}{y\tpAnno{B}})$.
    Fix $\Gamma \subseteq \Delta$ and let $a$ be a term such that $\comp{\Delta}{A}(a)$.
    By the induction hypothesis, $a$ can be reified into a normal form.
    Since we also have $\neu{\Delta}{A \to B}(t)$, $\neu{\Delta}{B}(\tmApp{t}{a}{y\tpAnno{B}})$ follows by definition; then the induction hypothesis gives the required result.

    Now, suppose that $\comp{\Gamma}{A \to B}(t)$.
    There are two cases to consider: (1) $t$ is convertible to $\tmAbort{e}$ for some term $e$ such that $\comp{\Gamma}{\tpEmp}(e)$, or (2) $t$ is convertible to $\tmLam{x}{b}$ for some term $b$ such that for all $\Gamma \subseteq \Delta$, if $\comp{\Delta}{A}(a)$, then $\comp{\Delta}{B}(b[a/x])$.

    Case (1) is analogous the previous case pertaining to $\tmAbort{e}$.
    In Case (2), it suffices to show that $b$ can be reified into a normal form.
    Choose $\Gamma \subseteq \Gamma,x : A$.
    By definition, every variable is a neutral element, \ie $\neu{\Gamma,x : A}{A}(x)$; hence it can be reflected into a computable element by the induction hypothesis, so we have $\comp{\Gamma,x : A}{B}(b[x/x])$.
    Note that $b[x/x] = b$; hence $b$ is convertible to a normal form by the induction hypothesis.
  \end{itemize}
\end{proof}

\begin{figure}
  \centering
  \begin{mathpar}
    \ebrule[\rVar]{
      \hypo{x : A \in \Gamma}
      \infer1{\Gamma \vdash x : A}
    }\and
    \ebrule[\rEmpE]{
      \hypo{\Gamma \vdash e : \tpEmp}
      \infer1{\Gamma \vdash \tmAbort{e} : A}
    }\and
    \ebrule[\rProdI]{
      \hypo{\Gamma \vdash a : A}
      \hypo{\Gamma \vdash b : B}
      \infer2{\Gamma \vdash \tmPair{a}{b} : A \times B}
    }\and
    \ebrule[\rProdE]{
      \hypo{\Gamma \vdash p : A \times B}
      \hypo{\Gamma,x:A,y:B \vdash c : C}
      \infer2{\Gamma \vdash \tmDestruct{p}{c} : C}
    }\and
    \ebrule[\rSumIl]{
      \hypo{\Gamma \vdash a : A}
      \infer1{\Gamma \vdash \tmInl{a} : A + B}
    }\and
    \ebrule[\rSumIr]{
      \hypo{\Gamma \vdash b : B}
      \infer1{\Gamma \vdash \tmInr{b} : A + B}
    }\and
    \ebrule[\rSumE]{
      \hypo{\Gamma \vdash s : A + B}
      \hypo{\Gamma, x : A \vdash c : C}
      \hypo{\Gamma, y : B \vdash c' : C}
      \infer3{\Gamma \vdash \tmCase{s}{c}{c'} : C}
    }\and
    \ebrule[\rFunI]{
      \hypo{\Gamma, x : A \vdash t : B}
      \infer1{\Gamma \vdash \tmLam{x}{t} : A \to B}
    }\and
    \ebrule[\rFunE]{
      \hypo{\Gamma \vdash f : A \to B}
      \hypo{\Gamma \vdash a : A}
      \hypo{\Gamma,y:B \vdash c : C}
      \infer3{\Gamma \vdash \tmApp{f}{a}{c} : C}
    }
  \end{mathpar}
  \caption{Typing rules}
  \label{fig:0000}
\end{figure}

\begin{figure}
  \centering
  \begin{mathpar}
    \ebrule[\rEmpe]{
      \hypo{\Gamma \vdash e : \tpEmp}
      \infer1{\Gamma \vdash e = \tmAbort{e} : \tpEmp}
    }\and
    \ebrule[\rs]{
      \hypo{\Delta \vdash t : A}
      \hypo{\Gamma \vdash e : \tpEmp}
      \hypo{\Gamma \subseteq \Delta}
      \infer3{\Delta \vdash t = \tmAbort{e} : A}
    }\and
    \ebrule[\rProdb]{
      \hypo{\Gamma \vdash a : A}
      \hypo{\Gamma \vdash b : B}
      \hypo{\Gamma,x : A, y : B \vdash c}
      \infer3{\Gamma \vdash \tmDestruct{\tmPair{a}{b}}{c} = c[a/x,b/y] : C}
    }\and
    \ebrule[\rProde]{
      \hypo{\Gamma \vdash p : A \times B}
      \infer1{\Gamma \vdash p = \tmPair{\tmDestruct{p}{x\tpAnno{A}}}{\tmDestruct{p}{y\tpAnno{B}}} : A \times B}
    }\and
    \ebrule[\rProdsa]{
      \hypo{%
        \begin{matrix}
          \Gamma \vdash p : C \times D\\
          \Gamma,n : C,m : D \vdash c : A \times B\\
          \Gamma,x : A,y : B \vdash d : E
        \end{matrix}
      }
      \infer1{\Gamma \vdash \tmDestruct{\tmDestruct{p}{c}}{d} = \tmDestruct{p}{\tmDestruct{c}{d}} : E}
    }\and
    \ebrule[\rProdsb]{
      \hypo{%
        \begin{matrix}
          \Gamma \vdash s : C + D\\
          \Gamma,n : C \vdash c : A \times B
        \end{matrix}
      }
      \hypo{%
        \begin{matrix}
          \Gamma,m : D \vdash c' : A \times B\\
          \Gamma,x : A,y : B \vdash d : E
        \end{matrix}
      }
      \infer2{%
        \Gamma \vdash \tmDestruct{\tmCase{s}{c}{c'}}{d} = \tmCase{s}{\tmDestruct{c}{d}}{\tmDestruct{c'}{d}} : E
      }
    }\and
    \ebrule[\rProdsc]{
      \hypo{
        \begin{matrix}
          \Gamma \vdash f : A \to B\\
          \Gamma \vdash a : A
        \end{matrix}
      }
      \hypo{
        \begin{matrix}
          \Gamma,y : B \vdash b : C \times D\\
          \Gamma,n : C,m : D \vdash c : E
        \end{matrix}
      }
      \infer2{%
        \Gamma \vdash \tmDestruct{\tmApp{f}{a}{b}}{c} =
        \tmApp{f}{a}{\tmDestruct{b}{c}} : E}
    }\and
    \ebrule[\rSumbl]{
      \hypo{\Gamma \vdash a : A}
      \hypo{\Gamma,x : A \vdash c : C}
      \hypo{\Gamma,y : B \vdash c' : C}
      \infer3{\Gamma \vdash \tmCase{\tmInl{a}}{c}{c'} = c[a/x] : C}
    }\and
    \ebrule[\rSumbr]{
      \hypo{\Gamma \vdash b : B}
      \hypo{\Gamma,x : A \vdash c : C}
      \hypo{\Gamma,y : B \vdash c' : C}
      \infer3{\Gamma \vdash \tmCase{\tmInr{b}}{c}{c'} = c'[b/y] : C}
    }\and
    \ebrule[\rSume]{
      \hypo{\Gamma \vdash s : A + B}
      \infer1{\Gamma \vdash s = \tmCase{s}{\tmInl{x\tpAnno{A}}}{\tmInr{y\tpAnno{B}}} : A + B}
    }\and
    \ebrule[\rFunb]{
      \hypo{\Gamma,x : A \vdash b : B}
      \hypo{\Gamma \vdash a : A}
      \hypo{\Gamma,y : B \vdash c : C}
      \infer3{\Gamma \vdash \tmApp{\tmLam{x}{b}}{a}{c} = c[b[a/x]/y] : C}
    }\and
    \ebrule[\rFune]{
      \hypo{\Gamma \vdash f : A \to B}
      \infer1{\Gamma \vdash f = \tmLam{x}{\tmApp{f}{x\tpAnno{A}}{y\tpAnno{B}}} : A \to B}
    }
  \end{mathpar}
  \caption{Equational axioms of LC}
  \label{fig:0003}
\end{figure}

\bibliography{bib}
\bibliographystyle{alpha}

\end{document}
