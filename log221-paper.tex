\documentclass[a4paper]{article}

\usepackage{preamble}
\usepackage{log221-paper-macros}
\usepackage{showkeys}

\title{Curry-Howard correspondence and proof simplification}
\author{Frank Tsai}

\begin{document}

\maketitle

\section{Introduction}
\label{sec:0000}

\section{Curry-Howard correspondence}
\label{sec:0001}

\begin{figure}
  \centering
  \begin{mathpar}
    \ebrule[\rVar]{
      \hypo{x : A \in \Gamma}
      \infer1{\Gamma \vdash x : A}
    }\and
    \ebrule[\rEmpE]{
      \hypo{\Gamma \vdash e : \tpEmp}
      \infer1{\Gamma \vdash \tmAbort{e} : A}
    }\and
    \ebrule[\rProdI]{
      \hypo{\Gamma \vdash a : A}
      \hypo{\Gamma \vdash b : B}
      \infer2{\Gamma \vdash \tmPair{a}{b} : A \times B}
    }\and
    \ebrule[\rProdEl]{
      \hypo{\Gamma \vdash p : A \times B}
      \infer1{\Gamma \vdash \tmPrl{p} : A}
    }\and
    \ebrule[\rProdEr]{
      \hypo{\Gamma \vdash p : A \times B}
      \infer1{\Gamma \vdash \tmPrr{p} : B}
    }\and
    \ebrule[\rSumIl]{
      \hypo{\Gamma \vdash a : A}
      \infer1{\Gamma \vdash \tmInl{a} : A + B}
    }\and
    \ebrule[\rSumIr]{
      \hypo{\Gamma \vdash b : B}
      \infer1{\Gamma \vdash \tmInr{b} : A + B}
    }\and
    \ebrule[\rSumE]{
      \hypo{\Gamma \vdash s : A + B}
      \hypo{\Gamma, x : A \vdash c : C}
      \hypo{\Gamma, y : B \vdash c' : C}
      \infer3{\Gamma \vdash \tmCase{s}{c}{c'} : C}
    }\and
    \ebrule[\rFunI]{
      \hypo{\Gamma, x : A \vdash b : B}
      \infer1{\Gamma \vdash \tmLam{x : A}{b} : A \to B}
    }\and
    \ebrule[\rFunE]{
      \hypo{\Gamma \vdash f : A \to B}
      \hypo{\Gamma \vdash a : A}
      \infer2{\Gamma \vdash \tmApp{f}{a} : B}
    }
  \end{mathpar}
  \caption{Typing rules}
  \label{fig:0000}
\end{figure}

\begin{figure}
  \centering
  \begin{mathpar}
    \tmPrl{\tmPair{a}{b}} = a\and
    \tmPrr{\tmPair{a}{b}} = b\and
    \tmCase{\tmInl{a}}{c}{c'} = c[a/x]\and
    \tmCase{\tmInr{b}}{c}{c'} = c'[b/y]\and
    \tmApp{\tmLam{x : A}{b}}{a} = b[a/x]
  \end{mathpar}
  \caption{Equational axioms}
  \label{fig:0001}
\end{figure}

\subsection{From proofs to programs}
\label{sec:0002}

\subsection{From programs to proofs}
\label{sec:0003}

\subsection{Detour conversion and $\beta$-conversion}
\label{sec:0005}

\section{Normalization}
\label{sec:0004}

\subsection{Tait's method of computability}
\label{sec:0006}

\begin{axiom}[Synthetic computability]\label{ax:0000}
  A family of computability predicates have the following properties:
  \begin{enumerate}
  \item if $x : A \in \Gamma$, then $\neu{\Gamma}{A}(x)$;
  \item if $\neu{\Gamma}{A}(t)$, then $\comp{\Gamma}{A}(t)$;
  \item if $\comp{\Gamma}{A}(t)$, then $\norm(t)$;
  \item if $\comp{\Gamma}{A}(t)$ and $s \bRed t$, then $\comp{\Gamma}{A}(s)$.
  \end{enumerate}
\end{axiom}

\begin{axiom}\label{ax:0001}
  If $\Gamma \vdash t : A$ and $\comp{\Delta}{\Gamma}(\gamma)$, then $\comp{\Delta}{A}(t[\gamma])$.
\end{axiom}

\begin{theorem}[Normalization]\label{thm:0000}
  If $\Gamma \vdash t : A$, then $\norm(t)$.
\end{theorem}
\begin{proof}
  By an easy induction on the length of $\Gamma$ and \cref{ax:0000}, the identity substitution $\id{\Gamma}$ is computable; hence $t[\id{\Gamma}] \equiv t$ is computable by \cref{ax:0001}.
  Then by \cref{ax:0000}, $t$ is normalizing.
\end{proof}

\subsubsection{Substantiating the axioms}
\label{sec:0008}

\begin{definition}
  A \emph{neutral element} is either a variable or an eliminator whose major argument is a neutral element.
\end{definition}

\begin{construction}
  Normalizing neutral elements are generated by the following rules where $u$ ranges over neutral elements:
  \begin{mathpar}
    \ebrule{
      \hypo{x : A \in \Gamma}
      \infer1{\neu{\Gamma}{A}(x)}
    }\and
    \ebrule{
      \hypo{\neu{\Gamma}{A \times B}(u)}
      \infer1{\neu{\Gamma}{A}(\tmPrl{u})}
    }\and
    \ebrule{
      \hypo{\neu{\Gamma}{A \times B}(u)}
      \infer1{\neu{\Gamma}{B}(\tmPrr{u})}
    }\and
    \ebrule{
      \hypo{\neu{\Gamma}{A + B}(u)}
      \hypo{\norm(c\tpAnno{C})}
      \hypo{\norm(c'\tpAnno{C})}
      \infer3{\neu{\Gamma}{C}(\tmCase{u}{c}{c'})}
    }\and
    \ebrule{
      \hypo{\neu{\Gamma}{A \to B}(u)}
      \hypo{\norm(a)}
      \infer2{\neu{\Gamma}{B}(\tmApp{u}{a})}
    }
  \end{mathpar}
\end{construction}

\begin{lemma}\label{thm:0002}
  If $\neu{\Gamma}{A}(t)$, then $\norm(t)$.
\end{lemma}
\begin{proof}
  Straightforward induction on the derivation of $\neu{\Gamma}{A}(t)$.
\end{proof}

\begin{construction}
  Computable elements are generated by induction on types:
  \begin{itemize}
  \item[$\tpEmp$:] $\comp{\Gamma}{\tpEmp}(t)$ iff $\norm(t)$.
  \item[$A \times B$:] $\comp{\Gamma}{A \times B}(t)$ iff $\comp{\Gamma}{A}(\tmPrl{t})$ and $\comp{\Gamma}{B}(\tmPrr{t})$, or $t \bRed* \tmAbort{e}$ for some $e$ such that $\comp{\Gamma}{\tpEmp}(e)$.
  \item[$A + B$:] $\comp{\Gamma}{A + B}(t)$ iff $t \bRed* \tmInl{a}$ for some $a$ such that $\comp{\Gamma}{A}(a)$, or $t \bRed* \tmInl{b}$ for some $b$ such that $\comp{\Gamma}{B}(b)$, or $t \bRed* t'$ such that $\neu{\Gamma}{A + B}(t')$, or $t \bRed* \tmAbort{e}$ for some $e$ such that $\comp{\Gamma}{\tpEmp}(e)$.
  \item[$A \to B$:] $\comp{\Gamma}{A \to B}(t)$ iff for all $\Gamma \subseteq \Delta$, if $\comp{\Delta}{A}(a)$, then $\comp{\Delta}{B}(\tmApp{t}{a})$, or $t \bRed* \tmAbort{e}$ for some $e$ such that $\comp{\Gamma}{\tpEmp}(e)$.
  \end{itemize}
\end{construction}

\begin{lemma}
  \cref{ax:0000} holds.
\end{lemma}
\begin{proof}
  By induction on type.
  \begin{itemize}
  \item[$\tpEmp$:] (1) By definition, every variable in context is a normalizing neural element.
    (2) Suppose that $\neu{\Gamma}{A}(t)$, then $t$ is normalizing by \cref{thm:0002}; hence $\comp{\Gamma}{\tpEmp}(t)$ by definition.
    (3) If $\comp{\Gamma}{\tpEmp}(t)$, then $\norm(t)$ by definition.
    (4) This is immediate by transitivity.
  \item[$A \times B$:] (2) If $\neu{\Gamma}{A \times B}(t)$, then $\neu{\Gamma}{A}(\tmPrl{t})$ and $\neu{\Gamma}{B}(\tmPrr{t})$; then by the induction hypothesis, $\comp{\Gamma}{A}(\tmPrl{t})$ and $\comp{\Gamma}{B}(\tmPrr{t})$.
    Hence $\comp{\Gamma}{A \times B}(t)$ by definition.
    (3) If $\comp{\Gamma}{A \times B}(t)$, then there are two cases to consider.
    The second case is always trivial.
    In the first case, we have $\norm(\tmPrl{t})$ and $\norm(\tmPrr{t})$; hence $\norm(t)$ (reductions can only take place under the projections and the only interesting case is when $t = \tmPair{a}{b}$).
  \item[$A + B$:] (2) If $\neu{\Gamma}{A + B}(t)$, then by definition $\comp{\Gamma}{A + B}(t)$.
    (3) If $\comp{\Gamma}{A + B}(t)$, we consider two cases.
    If $t \bRed* \tmInl{a}$ for $\comp{\Gamma}{A}(a)$, then by the induction hypothesis, $\norm(a)$; hence $\norm(\tmInl{a})$ is evident.
    If $t \bRed* \neu{\Gamma}{A + B}(t')$, then $\norm(t')$ by \cref{thm:0002}; hence $t$ is normalizing.
  \end{itemize}
\end{proof}

We have verified this axiom so we can use it in the proof below.

\begin{lemma}
  \cref{ax:0001} holds.
\end{lemma}
\begin{proof}
  By induction on the typing derivation.
  \begin{itemize}
  \item[\rSumE:] We need to show $\comp{\Delta}{C}(\tmCase{s[\gamma]}{c[\gamma,x/x]}{c'[\gamma,y/y]})$.
    Since $\comp{\Delta}{A + B}(s[\gamma])$, we consider 3 cases.
    (1) If $s[\gamma] \bRed* \tmInl{a}$ and $\comp{\Delta}{A}(a)$, then since $\tmCase{s[\gamma]}{c[\gamma,x/x]}{c'[\gamma,y/y]} \bRed \tmCase{\tmInl{a}}{c[\gamma,x/x]}{c'[\gamma,y/y]} \bRed c[\gamma,a/x]$, it suffices to show $\comp{\Delta}{C}(c[\gamma,a/x])$.
    \comment{we need to pull head expansion out of axiom 1.}
    This is just the induction hypothesis since $\comp{\Delta}{\Gamma,x : A}(\gamma,a/x)$.
    If $s[\gamma] \bRed* t'$ where $t'$ is a normalizing neutral element, then it suffices to show that $c[\gamma,x/x]$ and $c'[\gamma,y/y]$ are normalizing.
    Since $\comp{\Delta}{A}(x)$ and $\comp{\Delta}{B}(y)$ by \cref{ax:0000}, we have $\comp{\Delta}{\Gamma,x : A}(\gamma,a/x)$ and $\comp{\Delta}{\Gamma,y : B}(\gamma,b/x)$.
    Then by the induction hypothesis, we have $\comp{\Delta}{C}(c[\gamma,a/x])$ and $\comp{\Delta}{C}(c[\gamma,b/y])$.
    Now apply \cref{ax:0000} again.
  \end{itemize}
\end{proof}
\section{Conclusion}
\label{sec:0007}



\bibliography{bib}
\bibliographystyle{alpha}

\end{document}
